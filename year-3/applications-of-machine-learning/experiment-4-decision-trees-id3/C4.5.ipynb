{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C4.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://gabrielelanaro.github.io/blog/2016/03/03/decision-trees.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# eps for making value a bit greater than 0 later on\n",
    "eps = np.finfo(float).eps\n",
    "\n",
    "from numpy import log2 as log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a dataset,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The input values\n",
    "x1 = [0, 1, 1, 2, 2, 2,3,2,1]\n",
    "x2 = [0, 0, 1, 1, 1, 0,2,2,1]\n",
    "# The class\n",
    "y = np.array([0, 0, 0, 1, 1, 0,1,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition(a):\n",
    "    return {c: (a==c).nonzero()[0] for c in np.unique(a)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(s):\n",
    "    res = 0\n",
    "    val, counts = np.unique(s, return_counts=True)\n",
    "    freqs = counts.astype('float')/len(s)\n",
    "    for p in freqs:\n",
    "        if p != 0.0:\n",
    "            res -= p * np.log2(p)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutual_information(y, x):\n",
    "\n",
    "    res = entropy(y)\n",
    "\n",
    "    # We partition x, according to attribute values x_i\n",
    "    val, counts = np.unique(x, return_counts=True)\n",
    "    freqs = counts.astype('float')/len(x)\n",
    "\n",
    "    # We calculate a weighted average of the entropy\n",
    "    for p, v in zip(freqs, val):\n",
    "        res -= p * entropy(y[x == v])\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutual_information(y, x):\n",
    "    res = entropy(y)\n",
    "\n",
    "    # We partition x, according to attribute values x_i\n",
    "    val, counts = np.unique(x, return_counts=True)\n",
    "    freqs = counts.astype('float')/len(x)\n",
    "\n",
    "    # We calculate a weighted average of the entropy\n",
    "    for p, v in zip(freqs, val):\n",
    "        res -= p * entropy(y[x == v])\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_pure(s):\n",
    "    return len(set(s)) == 1\n",
    "\n",
    "def recursive_split(x, y):\n",
    "    # If there could be no split, just return the original set\n",
    "    if is_pure(y) or len(y) == 0:\n",
    "        return y\n",
    "\n",
    "    # We get attribute that gives the highest mutual information\n",
    "    gain = np.array([mutual_information(y, x_attr) for x_attr in x.T])\n",
    "    selected_attr = np.argmax(gain)\n",
    "\n",
    "    # If there's no gain at all, nothing has to be done, just return the original set\n",
    "    if np.all(gain < 1e-6):\n",
    "        return y\n",
    "\n",
    "\n",
    "    # We split using the selected attribute\n",
    "    sets = partition(x[:, selected_attr])\n",
    "\n",
    "    res = {}\n",
    "    for k, v in sets.items():\n",
    "        y_subset = y.take(v, axis=0)\n",
    "        x_subset = x.take(v, axis=0)\n",
    "\n",
    "        res[\"x_%d = %d\" % (selected_attr, k)] = recursive_split(x_subset, y_subset)\n",
    "\n",
    "    return res\n",
    "\n",
    "X = np.array([x1, x2]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "c4_5 = recursive_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty(d, indent=0):\n",
    "    for key, value in d.items():\n",
    "        print('\\t' * indent + str(key))\n",
    "\n",
    "        if isinstance(value, dict):\n",
    "            pretty(value, indent+1)\n",
    "        else:\n",
    "            print('\\t' * (indent+1) + str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_1 = 0\n",
      "\t[0 0 0]\n",
      "x_1 = 1\n",
      "\tx_0 = 1\n",
      "\t\t[0 1]\n",
      "\tx_0 = 2\n",
      "\t\t[1 1]\n",
      "x_1 = 2\n",
      "\tx_0 = 2\n",
      "\t\t[0]\n",
      "\tx_0 = 3\n",
      "\t\t[1]\n"
     ]
    }
   ],
   "source": [
    "pretty(c4_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hellinger Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www.pythonexample.com/code/hellinger-distance-decision-tree/\n",
    "\n",
    "https://gist.github.com/larsmans/3116927\n",
    "\n",
    "http://videolectures.net/ecmlpkdd08_cieslak_ldtf/?q=hellinger%20distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three ways of computing the Hellinger distance between two discrete\n",
    "probability distributions using NumPy and SciPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import norm\n",
    "from scipy.spatial.distance import euclidean\n",
    " \n",
    "_SQRT2 = np.sqrt(2)     # sqrt(2) with default precision np.float64\n",
    "\n",
    "def hellinger_dist(p, q):\n",
    "    return np.sqrt(np.sum((np.sqrt(p) - np.sqrt(q)) ** 2)) / _SQRT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hellinger_dist(p, q):\n",
    "    return np.sqrt(np.sum((np.sqrt(p) - np.sqrt(q)) ** 2)) / _SQRT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The input values\n",
    "x1 = [0, 1, 1, 2, 2, 2, 1]\n",
    "x2 = [0, 0, 1, 1, 1, 0, 1]\n",
    "\n",
    "# The class\n",
    "y = np.array([0, 0, 0, 1, 1, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat = 1\n",
    "\n",
    "# p = np.array([.05, .05, .1, .1, .2, .2, .3] * repeat)\n",
    "# q = np.array([  0,   0,  0, .1, .3, .3 ,.3] * repeat)\n",
    "\n",
    "# p /= p.sum()\n",
    "# q /= q.sum()\n",
    "\n",
    "# hellinger_dist(p=p, q=q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The input values\n",
    "x1 = [0, 1, 1, 2, 2, 2, 1]\n",
    "x2 = [0, 0, 1, 1, 1, 0, 1]\n",
    "\n",
    "# The class\n",
    "y = np.array([0, 0, 0, 1, 1, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition(a):\n",
    "    return {c: (a==c).nonzero()[0] for c in np.unique(a)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "def is_pure(s):\n",
    "    return len(set(s)) == 1\n",
    "\n",
    "def recursive_split(x, y):\n",
    "    \n",
    "    # If there could be no split, just return the original set\n",
    "    if is_pure(y) or len(y) == 0:\n",
    "        return y\n",
    "\n",
    "    # We get attribute that gives the smallest distance\n",
    "    distance = np.array([hellinger_dist(y/y.sum(), x_attr/x_attr.sum()) for x_attr in x.T])\n",
    "    selected_attr = np.argmin(distance)\n",
    "\n",
    "    # If the distance is very less, nothing has to be done, just return the original set\n",
    "    if np.all(distance < 1e-6):\n",
    "        return y\n",
    "\n",
    "    # We split using the selected attribute\n",
    "    sets = partition(x[:, selected_attr])\n",
    "\n",
    "    res = {}\n",
    "    for k, v in sets.items():\n",
    "        y_subset = y.take(v, axis=0)\n",
    "        x_subset = x.take(v, axis=0)\n",
    "\n",
    "        res[\"x_%d = %d\" % (selected_attr, k)] = recursive_split(x_subset, y_subset)\n",
    "\n",
    "    return res\n",
    "\n",
    "X = np.array([x1, x2]).T\n",
    "hellinger = recursive_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print(d, indent=0):\n",
    "    for key, value in d.items():\n",
    "        print('\\t' * indent + str(key))\n",
    "        if isinstance(value, dict):\n",
    "            pretty(value, indent+1)\n",
    "        else:\n",
    "            print('\\t' * (indent+1) + str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_1 = 0\n",
      "\t[0 0 0]\n",
      "x_1 = 1\n",
      "\tx_0 = 1\n",
      "\t\t[0 0]\n",
      "\tx_0 = 2\n",
      "\t\t[1 1]\n"
     ]
    }
   ],
   "source": [
    "pretty_print(hellinger)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
