{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/volt/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/volt/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/volt/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# To download the tokenizer\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Download the lemmatizer\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# To download the corpus of stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Declare Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining our text data.\n",
    "> Aragorn, The Return of the King, Book 1, “Chapter II: The Passing of the Grey Company,” p. 794."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = \"A time may come soon, when none will return. Then there will be need of valour without renown, for none shall remember the deeds that are done in the last defense of your homes. Yet the deeds will not be less valiant because they are unpraised.\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting the sentences from our paragraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A time may come soon, when none will return.',\n",
       " 'Then there will be need of valour without renown, for none shall remember the deeds that are done in the last defense of your homes.',\n",
       " 'Yet the deeds will not be less valiant because they are unpraised.']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = nltk.sent_tokenize(paragraph)\n",
    "sentences"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting the words from our paragraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A',\n",
       " 'time',\n",
       " 'may',\n",
       " 'come',\n",
       " 'soon',\n",
       " ',',\n",
       " 'when',\n",
       " 'none',\n",
       " 'will',\n",
       " 'return',\n",
       " '.',\n",
       " 'Then',\n",
       " 'there',\n",
       " 'will',\n",
       " 'be',\n",
       " 'need',\n",
       " 'of',\n",
       " 'valour',\n",
       " 'without',\n",
       " 'renown',\n",
       " ',',\n",
       " 'for',\n",
       " 'none',\n",
       " 'shall',\n",
       " 'remember',\n",
       " 'the',\n",
       " 'deeds',\n",
       " 'that',\n",
       " 'are',\n",
       " 'done',\n",
       " 'in',\n",
       " 'the',\n",
       " 'last',\n",
       " 'defense',\n",
       " 'of',\n",
       " 'your',\n",
       " 'homes',\n",
       " '.',\n",
       " 'Yet',\n",
       " 'the',\n",
       " 'deeds',\n",
       " 'will',\n",
       " 'not',\n",
       " 'be',\n",
       " 'less',\n",
       " 'valiant',\n",
       " 'because',\n",
       " 'they',\n",
       " 'are',\n",
       " 'unpraised',\n",
       " '.']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = nltk.word_tokenize(paragraph)\n",
    "words"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop Words Removal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing them using list comprehension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sentences)):\n",
    "    # From a single sentence, store all the words \n",
    "    wordsInSentence = nltk.word_tokenize(sentences[i])\n",
    "    \n",
    "    # Filter out all the stop words\n",
    "    wordsInSentence = [word for word in wordsInSentence if word not in set(stopwords.words('english'))]\n",
    "    \n",
    "    # Remake the sentences after removing the stop words\n",
    "    sentences[i] = ' '.join(wordsInSentence)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how `sentences` looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A time may come soon , none return .',\n",
       " 'Then need valour without renown , none shall remember deeds done last defense homes .',\n",
       " 'Yet deeds less valiant unpraised .']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialising Stemmer object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming each word through each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sentences)):\n",
    "    # From a single sentence, store all the words \n",
    "    wordsInSentence = nltk.word_tokenize(sentences[i])\n",
    "    \n",
    "    # Stemming all the words\n",
    "    wordsInSentence = [stemmer.stem(word) for word in wordsInSentence]\n",
    "    \n",
    "    # Remaking the sentence after stemming\n",
    "    sentences[i] = ' '.join(wordsInSentence)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what sentences looks like after stemming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a time may come soon , none return .',\n",
       " 'then need valour without renown , none shall rememb deed done last defens home .',\n",
       " 'yet deed less valiant unprais .']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialising Lemmatizer object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatizing using list comprehension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sentences)):\n",
    "    # From a single sentence, store all the words \n",
    "    wordsInSentence = nltk.word_tokenize(sentences[i])\n",
    "    \n",
    "    # Lemmatizing all the words\n",
    "    wordsInSentence = [lemmatizer.lemmatize(word) for word in wordsInSentence]\n",
    "    \n",
    "    # Remaking the sentence after lemmatization\n",
    "    sentences[i] = ' '.join(wordsInSentence)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's sentences after lemmatization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a time may come soon , none return .',\n",
       " 'then need valour without renown , none shall rememb deed done last defens home .',\n",
       " 'yet deed le valiant unprais .']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
