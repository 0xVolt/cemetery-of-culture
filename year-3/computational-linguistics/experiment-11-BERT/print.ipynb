{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 10 - Implementing a Bidirectional Encoder Representation with Transformers (BERT) \n",
    "\n",
    "## About the BERT\n",
    "BERT stands for \"Bidirectional Encoder Representation with Transformers\". To put it in simple words BERT extracts patterns or representations from the data or word embeddings by passing it through an encoder. The encoder itself is a transformer architecture that is stacked together. It is a bidirectional transformer which means that during training it considers the context from both left and right of the vocabulary to extract patterns or representations.\n",
    "\n",
    "<!-- ![](./assets/images/BERT-encoder.webp) -->\n",
    "\n",
    "## Paradigms of Use\n",
    "BERT uses two training paradigms: Pre-training and Fine-tuning. \n",
    "\n",
    "During pre-training, the model is trained on a large dataset to extract patterns. This is generally an unsupervised learning task where the model is trained on an unlabelled dataset like the data from a big corpus like Wikipedia.  \n",
    "\n",
    "During fine-tuning the model is trained for downstream tasks like Classification, Text-Generation, Language Translation, Question-Answering, and so forth. Essentially, you can download a pre-trained model and then Transfer-learn the model on your data.\n",
    "\n",
    "## How does BERT work?\n",
    "BERT makes use of Transformer, an attention mechanism that learns contextual relations between words (or sub-words) in a text. In its vanilla form, Transformer includes two separate mechanisms — an encoder that reads the text input and a decoder that produces a prediction for the task. Since BERT’s goal is to generate a language model, only the encoder mechanism is necessary. The detailed workings of Transformer are described in a paper by Google.\n",
    "\n",
    "As opposed to directional models, which read the text input sequentially (left-to-right or right-to-left), the Transformer encoder reads the entire sequence of words at once. Therefore it is considered bidirectional, though it would be more accurate to say that it’s non-directional. This characteristic allows the model to learn the context of a word based on all of its surroundings (left and right of the word).\n",
    "\n",
    "When training language models, there is a challenge of defining a prediction goal. Many models predict the next word in a sequence (e.g. “The child came home from ___”), a directional approach which inherently limits context learning. To overcome this challenge, BERT uses two training strategies:\n",
    "\n",
    "### Masked LM (MLM)\n",
    "\n",
    "Before feeding word sequences into BERT, 15% of the words in each sequence are replaced with a [MASK] token. The model then attempts to predict the original value of the masked words, based on the context provided by the other, non-masked, words in the sequence. In technical terms, the prediction of the output words requires:\n",
    "1. Adding a classification layer on top of the encoder output.\n",
    "2. Multiplying the output vectors by the embedding matrix, transforming them into the vocabulary dimension.\n",
    "3. Calculating the probability of each word in the vocabulary with softmax.\n",
    "\n",
    "<!-- ![](./assets/images/BERT-architecture.webp) -->\n",
    "\n",
    "The BERT loss function takes into consideration only the prediction of the masked values and ignores the prediction of the non-masked words. As a consequence, the model converges slower than directional models, a characteristic which is offset by its increased context awareness.\n",
    "\n",
    "### Next Sentence Prediction (NSP)\n",
    "\n",
    "In the BERT training process, the model receives pairs of sentences as input and learns to predict if the second sentence in the pair is the subsequent sentence in the original document. During training, 50% of the inputs are a pair in which the second sentence is the subsequent sentence in the original document, while in the other 50% a random sentence from the corpus is chosen as the second sentence. The assumption is that the random sentence will be disconnected from the first sentence.\n",
    "\n",
    "To help the model distinguish between the two sentences in training, the input is processed in the following way before entering the model:\n",
    "\n",
    "1. A [CLS] token is inserted at the beginning of the first sentence and a [SEP] token is inserted at the end of each sentence.\n",
    "2. A sentence embedding indicating Sentence A or Sentence B is added to each token. Sentence embeddings are similar in concept to token embeddings with a vocabulary of 2.\n",
    "3. A positional embedding is added to each token to indicate its position in the sequence. The concept and implementation of positional embedding are presented in the Transformer paper.\n",
    "\n",
    "<!-- ![](./assets/images/BERT-with-modifications.webp) -->\n",
    "\n",
    "Source: BERT [Devlin et al., 2018], with modifications\n",
    "\n",
    "To predict if the second sentence is indeed connected to the first, the following steps are performed:\n",
    "\n",
    "1. The entire input sequence goes through the Transformer model.\n",
    "2. The output of the [CLS] token is transformed into a 2×1 shaped vector, using a simple classification layer (learned matrices of weights and biases).\n",
    "3. Calculating the probability of IsNextSequence with softmax.\n",
    "\n",
    "When training the BERT model, Masked LM and Next Sentence Prediction are trained together, with the goal of minimizing the combined loss function of the two strategies.\n",
    "\n",
    "### Special tags for the tokens pre-defined by BERT\n",
    "BERT takes special tokens during training. Here is a table explaining the purpose of various tokens:\n",
    "|                                            Token                                            |                        Purpose                       |\n",
    "|:-------------------------------------------------------------------------------------------:|:----------------------------------------------------:|\n",
    "| [CLS]                                                                                       |       The first token is always classification       |\n",
    "| [SEP]                                                                                       |                Separates two sentences               |\n",
    "| [END]                                                                                       |                   End the sentence.                  |\n",
    "| [PAD]                                                                                       |    Use to truncate the sentence with equal length.   |\n",
    "|                                            [MASK]                                           | Use to create a mask by replacing the original word. |\n",
    "\n",
    "## How to use BERT (Fine-tuning)\n",
    "\n",
    "Using BERT for a specific task is relatively straightforward:\n",
    "\n",
    "BERT can be used for a wide variety of language tasks, while only adding a small layer to the core model:\n",
    "\n",
    "1. Classification tasks such as sentiment analysis are done similarly to Next Sentence classification, by adding a classification layer on top of the Transformer output for the [CLS] token.\n",
    "2. In Question Answering tasks (e.g. SQuAD v1.1), the software receives a question regarding a text sequence and is required to mark the answer in the sequence. Using BERT, a Q&A model can be trained by learning two extra vectors that mark the beginning and the end of the answer.\n",
    "3. In Named Entity Recognition (NER), the software receives a text sequence and is required to mark the various types of entities (Person, Organization, Date, etc) that appear in the text. Using BERT, a NER model can be trained by feeding the output vector of each token into a classification layer that predicts the NER label.\n",
    "\n",
    "In the fine-tuning training, most hyper-parameters stay the same as in BERT training.\n",
    "\n",
    "## Summary\n",
    "\n",
    "BERT falls into a self-supervised model. That means, it can generate inputs and labels from the raw corpus without being explicitly programmed by humans. Remember the data it is trained on is unstructured.\n",
    "\n",
    "BERT was pre-trained with two specific tasks: Masked Language Model and Next sentence prediction. The former uses masked input like “the man [MASK] to the store” instead of “the man went to the store”. This restricts BERT to see the words next to it which allows it to learn bidirectional representations as much as possible making it much more flexible and reliable for several downstream tasks. The latter predicts whether the two sentences are contextually assigned to each other. \n",
    "\n",
    "<!-- ![](./assets/images/BERT-overview.webp) -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-20 16:05:07.193292: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-20 16:05:08.285342: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-20 16:05:08.285488: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-20 16:05:08.285496: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoModel, BertTokenizerFast"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define GPU Here if Available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the Corpus of Raw Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      0  Go until jurong point, crazy.. Available only ...\n",
       "1      0                      Ok lar... Joking wif u oni...\n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      0  U dun say so early hor... U c already then say...\n",
       "4      0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r\"./assets/data/spam-data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the Shape of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the Way Labels are Distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.865937\n",
       "1    0.134063\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].value_counts(normalize=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the Bar Plot for the Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['label'].value_counts(normalize=True).plot.bar()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the Data into Training, Testing and Validation Sets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train-test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrain, XTest, yTrain, yTest = train_test_split(data['text'], data['label'], random_state=42, test_size=0.3, stratify=data['label'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "XValidationTrain, XValidationTest, yValidationTrain, yValidationTest = train_test_split(\n",
    "    XTest, \n",
    "    yTest, \n",
    "    random_state=42, \n",
    "    test_size=0.5, \n",
    "    stratify=yTest\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and Import the Pre-trained BERT Model from Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Import the BERT-base pretrained model\n",
    "BERT = AutoModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Length of each Sequence of Text and Plot their Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get length of all the messages in the train set\n",
    "sequenceLength = [len(sample.split()) for sample in XTrain]\n",
    "\n",
    "pd.Series(sequenceLength).hist(bins = 30)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenise and Encode Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/volt/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2339: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Tokenize and encode sequences in the training set\n",
    "trainTokens = tokenizer.batch_encode_plus(\n",
    "    XTrain.tolist(),\n",
    "    max_length = 25,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "# Tokenize and encode sequences in the validation set\n",
    "validationTokens = tokenizer.batch_encode_plus(\n",
    "    XValidationTrain.tolist(),\n",
    "    max_length = 25,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "# Tokenize and encode sequences in the test set\n",
    "testTokens = tokenizer.batch_encode_plus(\n",
    "    XValidationTest.tolist(),\n",
    "    max_length = 25,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.tokenization_utils_base.BatchEncoding"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(trainTokens)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert these Lists to Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSequenceTensor = torch.tensor(trainTokens['input_ids'])\n",
    "trainMaskTensor = torch.tensor(trainTokens['attention_mask'])\n",
    "trainYTensor = torch.tensor(yTrain.tolist())\n",
    "\n",
    "validationSequenceTensor = torch.tensor(validationTokens['input_ids'])\n",
    "validationMaskTensor = torch.tensor(validationTokens['attention_mask'])\n",
    "validationYTensor = torch.tensor(yValidationTrain.tolist())\n",
    "\n",
    "testSequenceTensor = torch.tensor(testTokens['input_ids'])\n",
    "testMaskTensor = torch.tensor(testTokens['attention_mask'])\n",
    "testYTensor = torch.tensor(yValidationTest.tolist())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here're the Created Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  101,  3125,   999,  ...,  1037,  3413,   102],\n",
       "         [  101,  1045,  2123,  ...,     0,     0,     0],\n",
       "         [  101,  9779,  2232,  ...,     0,     0,     0],\n",
       "         ...,\n",
       "         [  101,  2469,  1010,  ...,  1998,  3227,   102],\n",
       "         [  101,  2498,  2021,  ...,  2253, 11047,   102],\n",
       "         [  101,  7087,  1012,  ...,  2061,  1045,   102]]),\n",
       " torch.Size([3900, 25]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainSequenceTensor, trainSequenceTensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  101,  4067,  2017,  ...,     0,     0,     0],\n",
       "         [  101,  6203,  5718,  ...,  2345,  3535,   102],\n",
       "         [  101,  2073,  2024,  ...,     0,     0,     0],\n",
       "         ...,\n",
       "         [  101,  2053,  1012,  ...,  4309,  2489,   102],\n",
       "         [  101,  1015,  1045,  ...,  1005,  1040,   102],\n",
       "         [  101,  2524,  2444,  ..., 21472, 21472,   102]]),\n",
       " torch.Size([836, 25]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testSequenceTensor, testSequenceTensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  101,  5003,  2132,  ...,     0,     0,     0],\n",
       "         [  101, 11948,  2072,  ...,  1012, 20228,   102],\n",
       "         [  101, 13433,  2139,  ...,  2050,  1012,   102],\n",
       "         ...,\n",
       "         [  101,  2053,  3291,  ...,     0,     0,     0],\n",
       "         [  101,  1998,  2011,  ...,     0,     0,     0],\n",
       "         [  101,  2002,  2758,  ...,  1055,  5791,   102]]),\n",
       " torch.Size([836, 25]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validationSequenceTensor, validationSequenceTensor.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the Data Loader in PyTorch to Load the Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Hyper-parameter(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSize = 16"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Training Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapping the training tensors\n",
    "trainingTensor = TensorDataset(trainSequenceTensor, trainMaskTensor, trainYTensor)\n",
    "\n",
    "# Randomly Sampling the Wrapped Tensor\n",
    "trainingSampler = RandomSampler(trainingTensor)\n",
    "\n",
    "# Putting the training sampled data in a data loader\n",
    "trainingDataLoader = DataLoader(trainingTensor, sampler=trainingSampler, batch_size=batchSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.utils.data.dataset.TensorDataset,\n",
       " torch.utils.data.sampler.RandomSampler,\n",
       " torch.utils.data.dataloader.DataLoader)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(trainingTensor), type(trainingSampler), type(trainingDataLoader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, the same for Validation Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapping the validation tensors\n",
    "validationTensor = TensorDataset(validationSequenceTensor, validationMaskTensor, validationYTensor)\n",
    "\n",
    "# Randomly Sampling the Wrapped Tensor\n",
    "validationSampler = RandomSampler(validationTensor)\n",
    "\n",
    "# Putting the training sampled data in a data loader\n",
    "validationDataLoader = DataLoader(validationTensor, sampler=validationSampler, batch_size=batchSize)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct the BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all the parameters\n",
    "for parameter in BERT.parameters():\n",
    "    parameter.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTArchitecture(nn.Module):\n",
    "    def __init__(self, bert):\n",
    "        super(BERTArchitecture, self).__init__()\n",
    "        \n",
    "        self.bert = bert \n",
    "        \n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "      \n",
    "        # ReLU activation function\n",
    "        self.relu =  nn.ReLU()\n",
    "\n",
    "        # Dense layer 1\n",
    "        self.fullyConnected1 = nn.Linear(768, 512)\n",
    "      \n",
    "        # Dense layer 2 (Output layer)\n",
    "        self.fullyConnected2 = nn.Linear(512, 2)\n",
    "\n",
    "        # Softmax activation function\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    # Define the forward pass\n",
    "    def forward(self, sent_id, mask):\n",
    "        # Pass the inputs to the model  \n",
    "        _, cls_hs = self.bert(sent_id, attention_mask=mask, return_dict=False)\n",
    "      \n",
    "        # Input layer\n",
    "        x = self.fullyConnected1(cls_hs)\n",
    "\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Output layer\n",
    "        x = self.fullyConnected2(x)\n",
    "      \n",
    "        # Apply softmax activation\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pass the Pre-trained BERT from Huggingface to our Defined Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BERTArchitecture(BERT)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Push our Model to the Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an Optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/volt/.local/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Optimizer from hugging face transformers\n",
    "from transformers import AdamW\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: [0.57743559 3.72848948]\n"
     ]
    }
   ],
   "source": [
    "weightsList = compute_class_weight(class_weight='balanced', classes=np.unique(yTrain), y=yTrain)\n",
    "\n",
    "print(\"Class Weights:\", weightsList)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert Class Weights List to Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting list of class weights to a tensor\n",
    "weights = torch.tensor(weightsList, dtype=torch.float)\n",
    "\n",
    "# Push to GPU\n",
    "weights = weights.to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Hyper-parameters to Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function\n",
    "crossEntropy  = nn.NLLLoss(weight=weights) \n",
    "\n",
    "# Define the number of training epochs\n",
    "epochs = 50\n",
    "\n",
    "# Define how many steps before printing an update\n",
    "trainingStepsUpdate = 20\n",
    "validationStepsUpdate = 10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model - Fine Tuning\n",
    "Define a function to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    totalLoss = 0\n",
    "  \n",
    "    # Empty list to save model predictions\n",
    "    totalPredictions = []\n",
    "  \n",
    "    # Iterate over batches\n",
    "    for step, batch in enumerate(trainingDataLoader):\n",
    "        # Progress update after every 50 batches.\n",
    "        if step % trainingStepsUpdate == 0 and not step == 0:\n",
    "            print('\\tBatch {:>3,} of {:>3,}.'.format(step, len(trainingDataLoader)))\n",
    "        \n",
    "        # Push the batch to gpu\n",
    "        batch = [r.to(device) for r in batch]\n",
    " \n",
    "        sent_id, mask, labels = batch\n",
    "        \n",
    "        # Clear previously calculated gradients \n",
    "        model.zero_grad()        \n",
    "\n",
    "        # Get model predictions for the current batch\n",
    "        preds = model(sent_id, mask)\n",
    "\n",
    "        # Compute the loss between actual and predicted values\n",
    "        loss = crossEntropy(preds, labels)\n",
    "\n",
    "        # Add on to the total loss\n",
    "        totalLoss = totalLoss + loss.item()\n",
    "\n",
    "        # Backward pass to calculate the gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Model predictions are stored on GPU. So, push it to CPU\n",
    "        preds = preds.detach().cpu().numpy()\n",
    "\n",
    "    # Append the model predictions\n",
    "    totalPredictions.append(preds)\n",
    "\n",
    "    # Compute the training loss of the epoch\n",
    "    averageLoss = totalLoss / len(trainingDataLoader)\n",
    "  \n",
    "    # Predictions are in the form of (no. of batches, size of batch, no. of classes). Reshape the predictions in form of (number of samples, no. of classes)\n",
    "    totalPredictions  = np.concatenate(totalPredictions, axis=0)\n",
    "\n",
    "    # Returns the loss and predictions\n",
    "    return averageLoss, totalPredictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the Model - Using the Validation Set\n",
    "Define a function to evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    print(\"\\nEvaluating...\")\n",
    "  \n",
    "    # Deactivate dropout layers\n",
    "    model.eval()\n",
    "\n",
    "    totalLoss = 0\n",
    "    \n",
    "    # Empty list to save the model predictions\n",
    "    totalPredictions = []\n",
    "\n",
    "    # Iterate over batches\n",
    "    for step, batch in enumerate(validationDataLoader):\n",
    "        # Progress update every 50 batches.\n",
    "        if step % validationStepsUpdate == 0 and not step == 0:\n",
    "            # Report progress.\n",
    "            print('\\tBatch {:>3,} of {:>3,}.'.format(step, len(validationDataLoader)))\n",
    "\n",
    "        # Push the batch to gpu\n",
    "        batch = [t.to(device) for t in batch]\n",
    "\n",
    "        sent_id, mask, labels = batch\n",
    "\n",
    "        # Deactivate autograd\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            # Model predictions\n",
    "            preds = model(sent_id, mask)\n",
    "\n",
    "            # Compute the validation loss between actual and predicted values\n",
    "            loss = crossEntropy(preds,labels)\n",
    "\n",
    "            totalLoss = totalLoss + loss.item()\n",
    "\n",
    "            preds = preds.detach().cpu().numpy()\n",
    "\n",
    "            totalPredictions.append(preds)\n",
    "\n",
    "    # Compute the validation loss of the epoch\n",
    "    averageLoss = totalLoss / len(validationDataLoader) \n",
    "\n",
    "    # Reshape the predictions in form of (number of samples, no. of classes)\n",
    "    totalPredictions  = np.concatenate(totalPredictions, axis=0)\n",
    "\n",
    "    return averageLoss, totalPredictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Model to Train and Evaluate\n",
    "Training and validating the model for 50 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 of 50\n",
      "\tBatch  20 of 244.\n",
      "\tBatch  40 of 244.\n",
      "\tBatch  60 of 244.\n",
      "\tBatch  80 of 244.\n",
      "\tBatch 100 of 244.\n",
      "\tBatch 120 of 244.\n",
      "\tBatch 140 of 244.\n",
      "\tBatch 160 of 244.\n",
      "\tBatch 180 of 244.\n",
      "\tBatch 200 of 244.\n",
      "\tBatch 220 of 244.\n",
      "\tBatch 240 of 244.\n",
      "\n",
      "Evaluating...\n",
      "\tBatch  10 of  53.\n",
      "\tBatch  20 of  53.\n",
      "\tBatch  30 of  53.\n",
      "\tBatch  40 of  53.\n",
      "\tBatch  50 of  53.\n",
      "\n",
      "Training Loss: 0.667\n",
      "Training Time Taken: 12.67 seconds\n",
      "Validation Loss: 0.637\n",
      "Validation Time Taken: 2.31 seconds\n",
      "\n",
      "Epoch 2 of 50\n",
      "\tBatch  20 of 244.\n",
      "\tBatch  40 of 244.\n",
      "\tBatch  60 of 244.\n",
      "\tBatch  80 of 244.\n",
      "\tBatch 100 of 244.\n",
      "\tBatch 120 of 244.\n",
      "\tBatch 140 of 244.\n",
      "\tBatch 160 of 244.\n",
      "\tBatch 180 of 244.\n",
      "\tBatch 200 of 244.\n",
      "\tBatch 220 of 244.\n",
      "\tBatch 240 of 244.\n",
      "\n",
      "Evaluating...\n",
      "\tBatch  10 of  53.\n",
      "\tBatch  20 of  53.\n",
      "\tBatch  30 of  53.\n",
      "\tBatch  40 of  53.\n",
      "\tBatch  50 of  53.\n",
      "\n",
      "Training Loss: 0.626\n",
      "Training Time Taken: 12.33 seconds\n",
      "Validation Loss: 0.601\n",
      "Validation Time Taken: 2.56 seconds\n",
      "\n",
      "Epoch 3 of 50\n",
      "\tBatch  20 of 244.\n",
      "\tBatch  40 of 244.\n",
      "\tBatch  60 of 244.\n",
      "\tBatch  80 of 244.\n",
      "\tBatch 100 of 244.\n",
      "\tBatch 120 of 244.\n",
      "\tBatch 140 of 244.\n",
      "\tBatch 160 of 244.\n",
      "\tBatch 180 of 244.\n",
      "\tBatch 200 of 244.\n",
      "\tBatch 220 of 244.\n",
      "\tBatch 240 of 244.\n",
      "\n",
      "Evaluating...\n",
      "\tBatch  10 of  53.\n",
      "\tBatch  20 of  53.\n",
      "\tBatch  30 of  53.\n",
      "\tBatch  40 of  53.\n",
      "\tBatch  50 of  53.\n",
      "\n",
      "Training Loss: 0.591\n",
      "Training Time Taken: 11.85 seconds\n",
      "Validation Loss: 0.567\n",
      "Validation Time Taken: 2.39 seconds\n",
      "\n",
      "Epoch 4 of 50\n",
      "\tBatch  20 of 244.\n",
      "\tBatch  40 of 244.\n",
      "\tBatch  60 of 244.\n",
      "\tBatch  80 of 244.\n",
      "\tBatch 100 of 244.\n",
      "\tBatch 120 of 244.\n",
      "\tBatch 140 of 244.\n",
      "\tBatch 160 of 244.\n",
      "\tBatch 180 of 244.\n",
      "\tBatch 200 of 244.\n",
      "\tBatch 220 of 244.\n",
      "\tBatch 240 of 244.\n",
      "\n",
      "Evaluating...\n",
      "\tBatch  10 of  53.\n",
      "\tBatch  20 of  53.\n",
      "\tBatch  30 of  53.\n",
      "\tBatch  40 of  53.\n",
      "\tBatch  50 of  53.\n",
      "\n",
      "Training Loss: 0.558\n",
      "Training Time Taken: 11.45 seconds\n",
      "Validation Loss: 0.538\n",
      "Validation Time Taken: 2.38 seconds\n",
      "\n",
      "Epoch 5 of 50\n",
      "\tBatch  20 of 244.\n",
      "\tBatch  40 of 244.\n",
      "\tBatch  60 of 244.\n",
      "\tBatch  80 of 244.\n",
      "\tBatch 100 of 244.\n",
      "\tBatch 120 of 244.\n",
      "\tBatch 140 of 244.\n",
      "\tBatch 160 of 244.\n",
      "\tBatch 180 of 244.\n",
      "\tBatch 200 of 244.\n",
      "\tBatch 220 of 244.\n",
      "\tBatch 240 of 244.\n",
      "\n",
      "Evaluating...\n",
      "\tBatch  10 of  53.\n",
      "\tBatch  20 of  53.\n",
      "\tBatch  30 of  53.\n",
      "\tBatch  40 of  53.\n",
      "\tBatch  50 of  53.\n",
      "\n",
      "Training Loss: 0.529\n",
      "Training Time Taken: 12.57 seconds\n",
      "Validation Loss: 0.501\n",
      "Validation Time Taken: 2.49 seconds\n",
      "\n",
      "Epoch 6 of 50\n",
      "\tBatch  20 of 244.\n",
      "\tBatch  40 of 244.\n",
      "\tBatch  60 of 244.\n",
      "\tBatch  80 of 244.\n",
      "\tBatch 100 of 244.\n",
      "\tBatch 120 of 244.\n",
      "\tBatch 140 of 244.\n",
      "\tBatch 160 of 244.\n",
      "\tBatch 180 of 244.\n",
      "\tBatch 200 of 244.\n",
      "\tBatch 220 of 244.\n",
      "\tBatch 240 of 244.\n",
      "\n",
      "Evaluating...\n",
      "\tBatch  10 of  53.\n",
      "\tBatch  20 of  53.\n",
      "\tBatch  30 of  53.\n",
      "\tBatch  40 of  53.\n",
      "\tBatch  50 of  53.\n",
      "\n",
      "Training Loss: 0.504\n",
      "Training Time Taken: 11.51 seconds\n",
      "Validation Loss: 0.475\n",
      "Validation Time Taken: 2.38 seconds\n",
      "\n",
      "Epoch 7 of 50\n",
      "\tBatch  20 of 244.\n",
      "\tBatch  40 of 244.\n",
      "\tBatch  60 of 244.\n",
      "\tBatch  80 of 244.\n",
      "\tBatch 100 of 244.\n",
      "\tBatch 120 of 244.\n",
      "\tBatch 140 of 244.\n",
      "\tBatch 160 of 244.\n",
      "\tBatch 180 of 244.\n",
      "\tBatch 200 of 244.\n",
      "\tBatch 220 of 244.\n",
      "\tBatch 240 of 244.\n",
      "\n",
      "Evaluating...\n",
      "\tBatch  10 of  53.\n",
      "\tBatch  20 of  53.\n",
      "\tBatch  30 of  53.\n",
      "\tBatch  40 of  53.\n",
      "\tBatch  50 of  53.\n",
      "\n",
      "Training Loss: 0.473\n",
      "Training Time Taken: 11.69 seconds\n",
      "Validation Loss: 0.455\n",
      "Validation Time Taken: 2.38 seconds\n",
      "\n",
      "Epoch 8 of 50\n",
      "\tBatch  20 of 244.\n",
      "\tBatch  40 of 244.\n",
      "\tBatch  60 of 244.\n",
      "\tBatch  80 of 244.\n",
      "\tBatch 100 of 244.\n",
      "\tBatch 120 of 244.\n",
      "\tBatch 140 of 244.\n",
      "\tBatch 160 of 244.\n",
      "\tBatch 180 of 244.\n",
      "\tBatch 200 of 244.\n",
      "\tBatch 220 of 244.\n",
      "\tBatch 240 of 244.\n",
      "\n",
      "Evaluating...\n",
      "\tBatch  10 of  53.\n",
      "\tBatch  20 of  53.\n",
      "\tBatch  30 of  53.\n",
      "\tBatch  40 of  53.\n",
      "\tBatch  50 of  53.\n",
      "\n",
      "Training Loss: 0.457\n",
      "Training Time Taken: 11.62 seconds\n",
      "Validation Loss: 0.438\n",
      "Validation Time Taken: 2.44 seconds\n",
      "\n",
      "Epoch 9 of 50\n",
      "\tBatch  20 of 244.\n",
      "\tBatch  40 of 244.\n",
      "\tBatch  60 of 244.\n",
      "\tBatch  80 of 244.\n",
      "\tBatch 100 of 244.\n",
      "\tBatch 120 of 244.\n",
      "\tBatch 140 of 244.\n",
      "\tBatch 160 of 244.\n",
      "\tBatch 180 of 244.\n",
      "\tBatch 200 of 244.\n",
      "\tBatch 220 of 244.\n",
      "\tBatch 240 of 244.\n",
      "\n",
      "Evaluating...\n",
      "\tBatch  10 of  53.\n",
      "\tBatch  20 of  53.\n",
      "\tBatch  30 of  53.\n",
      "\tBatch  40 of  53.\n",
      "\tBatch  50 of  53.\n",
      "\n",
      "Training Loss: 0.434\n",
      "Training Time Taken: 12.68 seconds\n",
      "Validation Loss: 0.409\n",
      "Validation Time Taken: 2.48 seconds\n",
      "\n",
      "Epoch 10 of 50\n",
      "\tBatch  20 of 244.\n",
      "\tBatch  40 of 244.\n",
      "\tBatch  60 of 244.\n",
      "\tBatch  80 of 244.\n",
      "\tBatch 100 of 244.\n",
      "\tBatch 120 of 244.\n",
      "\tBatch 140 of 244.\n",
      "\tBatch 160 of 244.\n",
      "\tBatch 180 of 244.\n",
      "\tBatch 200 of 244.\n",
      "\tBatch 220 of 244.\n",
      "\tBatch 240 of 244.\n",
      "\n",
      "Evaluating...\n",
      "\tBatch  10 of  53.\n",
      "\tBatch  20 of  53.\n",
      "\tBatch  30 of  53.\n",
      "\tBatch  40 of  53.\n",
      "\tBatch  50 of  53.\n",
      "\n",
      "Training Loss: 0.416\n",
      "Training Time Taken: 11.56 seconds\n",
      "Validation Loss: 0.401\n",
      "Validation Time Taken: 2.53 seconds\n",
      "\n",
      "Epoch 11 of 50\n",
      "\tBatch  20 of 244.\n",
      "\tBatch  40 of 244.\n",
      "\tBatch  60 of 244.\n",
      "\tBatch  80 of 244.\n",
      "\tBatch 100 of 244.\n",
      "\tBatch 120 of 244.\n",
      "\tBatch 140 of 244.\n",
      "\tBatch 160 of 244.\n",
      "\tBatch 180 of 244.\n",
      "\tBatch 200 of 244.\n",
      "\tBatch 220 of 244.\n",
      "\tBatch 240 of 244.\n",
      "\n",
      "Evaluating...\n",
      "\tBatch  10 of  53.\n",
      "\tBatch  20 of  53.\n",
      "\tBatch  30 of  53.\n",
      "\tBatch  40 of  53.\n",
      "\tBatch  50 of  53.\n",
      "\n",
      "Training Loss: 0.398\n",
      "Training Time Taken: 12.89 seconds\n",
      "Validation Loss: 0.386\n",
      "Validation Time Taken: 2.41 seconds\n",
      "\n",
      "Epoch 12 of 50\n",
      "\tBatch  20 of 244.\n",
      "\tBatch  40 of 244.\n",
      "\tBatch  60 of 244.\n",
      "\tBatch  80 of 244.\n",
      "\tBatch 100 of 244.\n",
      "\tBatch 120 of 244.\n",
      "\tBatch 140 of 244.\n",
      "\tBatch 160 of 244.\n",
      "\tBatch 180 of 244.\n",
      "\tBatch 200 of 244.\n",
      "\tBatch 220 of 244.\n",
      "\tBatch 240 of 244.\n",
      "\n",
      "Evaluating...\n",
      "\tBatch  10 of  53.\n",
      "\tBatch  20 of  53.\n",
      "\tBatch  30 of  53.\n",
      "\tBatch  40 of  53.\n",
      "\tBatch  50 of  53.\n",
      "\n",
      "Training Loss: 0.397\n",
      "Training Time Taken: 11.73 seconds\n",
      "Validation Loss: 0.387\n",
      "Validation Time Taken: 2.39 seconds\n",
      "\n",
      "Epoch 13 of 50\n",
      "\tBatch  20 of 244.\n",
      "\tBatch  40 of 244.\n",
      "\tBatch  60 of 244.\n",
      "\tBatch  80 of 244.\n",
      "\tBatch 100 of 244.\n",
      "\tBatch 120 of 244.\n",
      "\tBatch 140 of 244.\n",
      "\tBatch 160 of 244.\n",
      "\tBatch 180 of 244.\n",
      "\tBatch 200 of 244.\n",
      "\tBatch 220 of 244.\n",
      "\tBatch 240 of 244.\n",
      "\n",
      "Evaluating...\n",
      "\tBatch  10 of  53.\n",
      "\tBatch  20 of  53.\n",
      "\tBatch  30 of  53.\n",
      "\tBatch  40 of  53.\n",
      "\tBatch  50 of  53.\n",
      "\n",
      "Training Loss: 0.373\n",
      "Training Time Taken: 11.93 seconds\n",
      "Validation Loss: 0.353\n",
      "Validation Time Taken: 2.36 seconds\n",
      "\n",
      "Epoch 14 of 50\n",
      "\tBatch  20 of 244.\n",
      "\tBatch  40 of 244.\n",
      "\tBatch  60 of 244.\n",
      "\tBatch  80 of 244.\n",
      "\tBatch 100 of 244.\n",
      "\tBatch 120 of 244.\n",
      "\tBatch 140 of 244.\n",
      "\tBatch 160 of 244.\n",
      "\tBatch 180 of 244.\n",
      "\tBatch 200 of 244.\n",
      "\tBatch 220 of 244.\n",
      "\tBatch 240 of 244.\n",
      "\n",
      "Evaluating...\n",
      "\tBatch  10 of  53.\n",
      "\tBatch  20 of  53.\n",
      "\tBatch  30 of  53.\n",
      "\tBatch  40 of  53.\n",
      "\tBatch  50 of  53.\n",
      "\n",
      "Training Loss: 0.359\n",
      "Training Time Taken: 12.72 seconds\n",
      "Validation Loss: 0.342\n",
      "Validation Time Taken: 2.43 seconds\n",
      "\n",
      "Epoch 15 of 50\n",
      "\tBatch  20 of 244.\n",
      "\tBatch  40 of 244.\n",
      "\tBatch  60 of 244.\n",
      "\tBatch  80 of 244.\n",
      "\tBatch 100 of 244.\n",
      "\tBatch 120 of 244.\n",
      "\tBatch 140 of 244.\n",
      "\tBatch 160 of 244.\n",
      "\tBatch 180 of 244.\n",
      "\tBatch 200 of 244.\n",
      "\tBatch 220 of 244.\n",
      "\tBatch 240 of 244.\n",
      "\n",
      "Evaluating...\n",
      "\tBatch  10 of  53.\n",
      "\tBatch  20 of  53.\n",
      "\tBatch  30 of  53.\n",
      "\tBatch  40 of  53.\n",
      "\tBatch  50 of  53.\n",
      "\n",
      "Training Loss: 0.352\n",
      "Training Time Taken: 11.91 seconds\n",
      "Validation Loss: 0.335\n",
      "Validation Time Taken: 2.33 seconds\n",
      "\n",
      "Epoch 16 of 50\n",
      "\tBatch  20 of 244.\n",
      "\tBatch  40 of 244.\n",
      "\tBatch  60 of 244.\n",
      "\tBatch  80 of 244.\n",
      "\tBatch 100 of 244.\n",
      "\tBatch 120 of 244.\n",
      "\tBatch 140 of 244.\n",
      "\tBatch 160 of 244.\n",
      "\tBatch 180 of 244.\n",
      "\tBatch 200 of 244.\n",
      "\tBatch 220 of 244.\n",
      "\tBatch 240 of 244.\n",
      "\n",
      "Evaluating...\n",
      "\tBatch  10 of  53.\n",
      "\tBatch  20 of  53.\n",
      "\tBatch  30 of  53.\n",
      "\tBatch  40 of  53.\n",
      "\tBatch  50 of  53.\n",
      "\n",
      "Training Loss: 0.338\n",
      "Training Time Taken: 11.33 seconds\n",
      "Validation Loss: 0.325\n",
      "Validation Time Taken: 2.33 seconds\n",
      "\n",
      "Epoch 17 of 50\n",
      "\tBatch  20 of 244.\n",
      "\tBatch  40 of 244.\n",
      "\tBatch  60 of 244.\n",
      "\tBatch  80 of 244.\n",
      "\tBatch 100 of 244.\n",
      "\tBatch 120 of 244.\n",
      "\tBatch 140 of 244.\n",
      "\tBatch 160 of 244.\n",
      "\tBatch 180 of 244.\n",
      "\tBatch 200 of 244.\n",
      "\tBatch 220 of 244.\n",
      "\tBatch 240 of 244.\n",
      "\n",
      "Evaluating...\n",
      "\tBatch  10 of  53.\n",
      "\tBatch  20 of  53.\n",
      "\tBatch  30 of  53.\n",
      "\tBatch  40 of  53.\n",
      "\tBatch  50 of  53.\n",
      "\n",
      "Training Loss: 0.326\n",
      "Training Time Taken: 11.70 seconds\n",
      "Validation Loss: 0.309\n",
      "Validation Time Taken: 2.72 seconds\n",
      "\n",
      "Epoch 18 of 50\n",
      "\tBatch  20 of 244.\n",
      "\tBatch  40 of 244.\n",
      "\tBatch  60 of 244.\n",
      "\tBatch  80 of 244.\n",
      "\tBatch 100 of 244.\n",
      "\tBatch 120 of 244.\n",
      "\tBatch 140 of 244.\n",
      "\tBatch 160 of 244.\n",
      "\tBatch 180 of 244.\n",
      "\tBatch 200 of 244.\n",
      "\tBatch 220 of 244.\n",
      "\tBatch 240 of 244.\n",
      "\n",
      "Evaluating...\n",
      "\tBatch  10 of  53.\n",
      "\tBatch  20 of  53.\n",
      "\tBatch  30 of  53.\n",
      "\tBatch  40 of  53.\n",
      "\tBatch  50 of  53.\n",
      "\n",
      "Training Loss: 0.309\n",
      "Training Time Taken: 11.52 seconds\n",
      "Validation Loss: 0.318\n",
      "Validation Time Taken: 2.40 seconds\n",
      "\n",
      "Epoch 19 of 50\n",
      "\tBatch  20 of 244.\n",
      "\tBatch  40 of 244.\n",
      "\tBatch  60 of 244.\n",
      "\tBatch  80 of 244.\n",
      "\tBatch 100 of 244.\n",
      "\tBatch 120 of 244.\n",
      "\tBatch 140 of 244.\n",
      "\tBatch 160 of 244.\n",
      "\tBatch 180 of 244.\n",
      "\tBatch 200 of 244.\n",
      "\tBatch 220 of 244.\n",
      "\tBatch 240 of 244.\n",
      "\n",
      "Evaluating...\n",
      "\tBatch  10 of  53.\n",
      "\tBatch  20 of  53.\n",
      "\tBatch  30 of  53.\n",
      "\tBatch  40 of  53.\n",
      "\tBatch  50 of  53.\n",
      "\n",
      "Training Loss: 0.322\n",
      "Training Time Taken: 10.39 seconds\n",
      "Validation Loss: 0.301\n",
      "Validation Time Taken: 2.12 seconds\n",
      "\n",
      "Epoch 20 of 50\n",
      "\tBatch  20 of 244.\n",
      "\tBatch  40 of 244.\n",
      "\tBatch  60 of 244.\n",
      "\tBatch  80 of 244.\n",
      "\tBatch 100 of 244.\n",
      "\tBatch 120 of 244.\n",
      "\tBatch 140 of 244.\n",
      "\tBatch 160 of 244.\n",
      "\tBatch 180 of 244.\n",
      "\tBatch 200 of 244.\n",
      "\tBatch 220 of 244.\n",
      "\tBatch 240 of 244.\n",
      "\n",
      "Evaluating...\n",
      "\tBatch  10 of  53.\n",
      "\tBatch  20 of  53.\n",
      "\tBatch  30 of  53.\n",
      "\tBatch  40 of  53.\n",
      "\tBatch  50 of  53.\n",
      "\n",
      "Training Loss: 0.310\n",
      "Training Time Taken: 10.39 seconds\n",
      "Validation Loss: 0.280\n",
      "Validation Time Taken: 2.12 seconds\n",
      "\n",
      "Epoch 21 of 50\n",
      "\tBatch  20 of 244.\n",
      "\tBatch  40 of 244.\n",
      "\tBatch  60 of 244.\n",
      "\tBatch  80 of 244.\n",
      "\tBatch 100 of 244.\n",
      "\tBatch 120 of 244.\n",
      "\tBatch 140 of 244.\n",
      "\tBatch 160 of 244.\n",
      "\tBatch 180 of 244.\n",
      "\tBatch 200 of 244.\n",
      "\tBatch 220 of 244.\n",
      "\tBatch 240 of 244.\n",
      "\n",
      "Evaluating...\n",
      "\tBatch  10 of  53.\n",
      "\tBatch  20 of  53.\n",
      "\tBatch  30 of  53.\n",
      "\tBatch  40 of  53.\n",
      "\tBatch  50 of  53.\n",
      "\n",
      "Training Loss: 0.299\n",
      "Training Time Taken: 10.35 seconds\n",
      "Validation Loss: 0.291\n",
      "Validation Time Taken: 2.15 seconds\n",
      "\n",
      "Epoch 22 of 50\n",
      "\tBatch  20 of 244.\n",
      "\tBatch  40 of 244.\n",
      "\tBatch  60 of 244.\n",
      "\tBatch  80 of 244.\n",
      "\tBatch 100 of 244.\n",
      "\tBatch 120 of 244.\n",
      "\tBatch 140 of 244.\n",
      "\tBatch 160 of 244.\n",
      "\tBatch 180 of 244.\n",
      "\tBatch 200 of 244.\n",
      "\tBatch 220 of 244.\n",
      "\tBatch 240 of 244.\n",
      "\n",
      "Evaluating...\n",
      "\tBatch  10 of  53.\n",
      "\tBatch  20 of  53.\n",
      "\tBatch  30 of  53.\n",
      "\tBatch  40 of  53.\n",
      "\tBatch  50 of  53.\n",
      "\n",
      "Training Loss: 0.291\n",
      "Training Time Taken: 10.35 seconds\n",
      "Validation Loss: 0.273\n",
      "Validation Time Taken: 2.12 seconds\n",
      "\n",
      "Epoch 23 of 50\n",
      "\tBatch  20 of 244.\n",
      "\tBatch  40 of 244.\n",
      "\tBatch  60 of 244.\n",
      "\tBatch  80 of 244.\n",
      "\tBatch 100 of 244.\n",
      "\tBatch 120 of 244.\n",
      "\tBatch 140 of 244.\n",
      "\tBatch 160 of 244.\n",
      "\tBatch 180 of 244.\n",
      "\tBatch 200 of 244.\n",
      "\tBatch 220 of 244.\n",
      "\tBatch 240 of 244.\n",
      "\n",
      "Evaluating...\n",
      "\tBatch  10 of  53.\n",
      "\tBatch  20 of  53.\n",
      "\tBatch  30 of  53.\n",
      "\tBatch  40 of  53.\n",
      "\tBatch  50 of  53.\n",
      "\n",
      "Training Loss: 0.284\n",
      "Training Time Taken: 10.97 seconds\n",
      "Validation Loss: 0.272\n",
      "Validation Time Taken: 2.70 seconds\n",
      "\n",
      "Epoch 24 of 50\n",
      "\tBatch  20 of 244.\n",
      "\tBatch  40 of 244.\n",
      "\tBatch  60 of 244.\n",
      "\tBatch  80 of 244.\n",
      "\tBatch 100 of 244.\n",
      "\tBatch 120 of 244.\n",
      "\tBatch 140 of 244.\n",
      "\tBatch 160 of 244.\n",
      "\tBatch 180 of 244.\n",
      "\tBatch 200 of 244.\n",
      "\tBatch 220 of 244.\n",
      "\tBatch 240 of 244.\n",
      "\n",
      "Evaluating...\n",
      "\tBatch  10 of  53.\n",
      "\tBatch  20 of  53.\n",
      "\tBatch  30 of  53.\n",
      "\tBatch  40 of  53.\n",
      "\tBatch  50 of  53.\n",
      "\n",
      "Training Loss: 0.278\n",
      "Training Time Taken: 10.83 seconds\n",
      "Validation Loss: 0.274\n",
      "Validation Time Taken: 2.12 seconds\n",
      "\n",
      "Epoch 25 of 50\n",
      "\tBatch  20 of 244.\n",
      "\tBatch  40 of 244.\n",
      "\tBatch  60 of 244.\n",
      "\tBatch  80 of 244.\n",
      "\tBatch 100 of 244.\n",
      "\tBatch 120 of 244.\n",
      "\tBatch 140 of 244.\n",
      "\tBatch 160 of 244.\n",
      "\tBatch 180 of 244.\n",
      "\tBatch 200 of 244.\n",
      "\tBatch 220 of 244.\n",
      "\tBatch 240 of 244.\n",
      "\n",
      "Evaluating...\n",
      "\tBatch  10 of  53.\n",
      "\tBatch  20 of  53.\n",
      "\tBatch  30 of  53.\n",
      "\tBatch  40 of  53.\n",
      "\tBatch  50 of  53.\n",
      "\n",
      "Training Loss: 0.275\n",
      "Training Time Taken: 10.48 seconds\n",
      "Validation Loss: 0.255\n",
      "Validation Time Taken: 2.24 seconds\n",
      "\n",
      "Epoch 26 of 50\n",
      "\tBatch  20 of 244.\n",
      "\tBatch  40 of 244.\n",
      "\tBatch  60 of 244.\n",
      "\tBatch  80 of 244.\n",
      "\tBatch 100 of 244.\n",
      "\tBatch 120 of 244.\n",
      "\tBatch 140 of 244.\n",
      "\tBatch 160 of 244.\n",
      "\tBatch 180 of 244.\n",
      "\tBatch 200 of 244.\n",
      "\tBatch 220 of 244.\n",
      "\tBatch 240 of 244.\n",
      "\n",
      "Evaluating...\n",
      "\tBatch  10 of  53.\n",
      "\tBatch  20 of  53.\n",
      "\tBatch  30 of  53.\n",
      "\tBatch  40 of  53.\n",
      "\tBatch  50 of  53.\n",
      "\n",
      "Training Loss: 0.261\n",
      "Training Time Taken: 10.27 seconds\n",
      "Validation Loss: 0.261\n",
      "Validation Time Taken: 2.16 seconds\n",
      "\n",
      "Epoch 27 of 50\n",
      "\tBatch  20 of 244.\n",
      "\tBatch  40 of 244.\n",
      "\tBatch  60 of 244.\n",
      "\tBatch  80 of 244.\n",
      "\tBatch 100 of 244.\n",
      "\tBatch 120 of 244.\n",
      "\tBatch 140 of 244.\n",
      "\tBatch 160 of 244.\n",
      "\tBatch 180 of 244.\n",
      "\tBatch 200 of 244.\n",
      "\tBatch 220 of 244.\n",
      "\tBatch 240 of 244.\n",
      "\n",
      "Evaluating...\n",
      "\tBatch  10 of  53.\n",
      "\tBatch  20 of  53.\n",
      "\tBatch  30 of  53.\n",
      "\tBatch  40 of  53.\n",
      "\tBatch  50 of  53.\n",
      "\n",
      "Training Loss: 0.260\n",
      "Training Time Taken: 11.62 seconds\n",
      "Validation Loss: 0.255\n",
      "Validation Time Taken: 2.73 seconds\n",
      "\n",
      "Epoch 28 of 50\n",
      "\tBatch  20 of 244.\n",
      "\tBatch  40 of 244.\n",
      "\tBatch  60 of 244.\n",
      "\tBatch  80 of 244.\n",
      "\tBatch 100 of 244.\n",
      "\tBatch 120 of 244.\n",
      "\tBatch 140 of 244.\n",
      "\tBatch 160 of 244.\n",
      "\tBatch 180 of 244.\n",
      "\tBatch 200 of 244.\n",
      "\tBatch 220 of 244.\n",
      "\tBatch 240 of 244.\n",
      "\n",
      "Evaluating...\n",
      "\tBatch  10 of  53.\n",
      "\tBatch  20 of  53.\n",
      "\tBatch  30 of  53.\n",
      "\tBatch  40 of  53.\n",
      "\tBatch  50 of  53.\n",
      "\n",
      "Training Loss: 0.253\n",
      "Training Time Taken: 13.29 seconds\n",
      "Validation Loss: 0.251\n",
      "Validation Time Taken: 2.58 seconds\n",
      "\n",
      "Epoch 29 of 50\n",
      "\tBatch  20 of 244.\n",
      "\tBatch  40 of 244.\n",
      "\tBatch  60 of 244.\n",
      "\tBatch  80 of 244.\n",
      "\tBatch 100 of 244.\n",
      "\tBatch 120 of 244.\n",
      "\tBatch 140 of 244.\n",
      "\tBatch 160 of 244.\n",
      "\tBatch 180 of 244.\n",
      "\tBatch 200 of 244.\n",
      "\tBatch 220 of 244.\n",
      "\tBatch 240 of 244.\n",
      "\n",
      "Evaluating...\n",
      "\tBatch  10 of  53.\n",
      "\tBatch  20 of  53.\n",
      "\tBatch  30 of  53.\n",
      "\tBatch  40 of  53.\n",
      "\tBatch  50 of  53.\n",
      "\n",
      "Training Loss: 0.248\n",
      "Training Time Taken: 11.89 seconds\n",
      "Validation Loss: 0.235\n",
      "Validation Time Taken: 2.46 seconds\n",
      "\n",
      "Epoch 30 of 50\n",
      "\tBatch  20 of 244.\n",
      "\tBatch  40 of 244.\n",
      "\tBatch  60 of 244.\n",
      "\tBatch  80 of 244.\n",
      "\tBatch 100 of 244.\n",
      "\tBatch 120 of 244.\n",
      "\tBatch 140 of 244.\n",
      "\tBatch 160 of 244.\n",
      "\tBatch 180 of 244.\n",
      "\tBatch 200 of 244.\n",
      "\tBatch 220 of 244.\n",
      "\tBatch 240 of 244.\n",
      "\n",
      "Evaluating...\n",
      "\tBatch  10 of  53.\n",
      "\tBatch  20 of  53.\n",
      "\tBatch  30 of  53.\n",
      "\tBatch  40 of  53.\n",
      "\tBatch  50 of  53.\n",
      "\n",
      "Training Loss: 0.242\n",
      "Training Time Taken: 12.09 seconds\n",
      "Validation Loss: 0.234\n",
      "Validation Time Taken: 2.46 seconds\n",
      "\n",
      "Epoch 31 of 50\n",
      "\tBatch  20 of 244.\n",
      "\tBatch  40 of 244.\n",
      "\tBatch  60 of 244.\n",
      "\tBatch  80 of 244.\n",
      "\tBatch 100 of 244.\n",
      "\tBatch 120 of 244.\n",
      "\tBatch 140 of 244.\n",
      "\tBatch 160 of 244.\n",
      "\tBatch 180 of 244.\n",
      "\tBatch 200 of 244.\n",
      "\tBatch 220 of 244.\n",
      "\tBatch 240 of 244.\n",
      "\n",
      "Evaluating...\n",
      "\tBatch  10 of  53.\n",
      "\tBatch  20 of  53.\n",
      "\tBatch  30 of  53.\n",
      "\tBatch  40 of  53.\n",
      "\tBatch  50 of  53.\n",
      "\n",
      "Training Loss: 0.240\n",
      "Training Time Taken: 12.54 seconds\n",
      "Validation Loss: 0.216\n",
      "Validation Time Taken: 2.29 seconds\n",
      "\n",
      "Epoch 32 of 50\n",
      "\tBatch  20 of 244.\n",
      "\tBatch  40 of 244.\n",
      "\tBatch  60 of 244.\n",
      "\tBatch  80 of 244.\n",
      "\tBatch 100 of 244.\n",
      "\tBatch 120 of 244.\n",
      "\tBatch 140 of 244.\n",
      "\tBatch 160 of 244.\n",
      "\tBatch 180 of 244.\n",
      "\tBatch 200 of 244.\n",
      "\tBatch 220 of 244.\n",
      "\tBatch 240 of 244.\n",
      "\n",
      "Evaluating...\n",
      "\tBatch  10 of  53.\n",
      "\tBatch  20 of  53.\n",
      "\tBatch  30 of  53.\n",
      "\tBatch  40 of  53.\n",
      "\tBatch  50 of  53.\n",
      "\n",
      "Training Loss: 0.234\n",
      "Training Time Taken: 10.83 seconds\n",
      "Validation Loss: 0.228\n",
      "Validation Time Taken: 2.16 seconds\n",
      "\n",
      "Epoch 33 of 50\n",
      "\tBatch  20 of 244.\n",
      "\tBatch  40 of 244.\n",
      "\tBatch  60 of 244.\n",
      "\tBatch  80 of 244.\n",
      "\tBatch 100 of 244.\n",
      "\tBatch 120 of 244.\n",
      "\tBatch 140 of 244.\n",
      "\tBatch 160 of 244.\n",
      "\tBatch 180 of 244.\n",
      "\tBatch 200 of 244.\n",
      "\tBatch 220 of 244.\n",
      "\tBatch 240 of 244.\n",
      "\n",
      "Evaluating...\n",
      "\tBatch  10 of  53.\n",
      "\tBatch  20 of  53.\n",
      "\tBatch  30 of  53.\n",
      "\tBatch  40 of  53.\n",
      "\tBatch  50 of  53.\n",
      "\n",
      "Training Loss: 0.225\n",
      "Training Time Taken: 10.96 seconds\n",
      "Validation Loss: 0.220\n",
      "Validation Time Taken: 2.17 seconds\n",
      "\n",
      "Epoch 34 of 50\n",
      "\tBatch  20 of 244.\n",
      "\tBatch  40 of 244.\n",
      "\tBatch  60 of 244.\n",
      "\tBatch  80 of 244.\n",
      "\tBatch 100 of 244.\n",
      "\tBatch 120 of 244.\n",
      "\tBatch 140 of 244.\n",
      "\tBatch 160 of 244.\n",
      "\tBatch 180 of 244.\n",
      "\tBatch 200 of 244.\n",
      "\tBatch 220 of 244.\n",
      "\tBatch 240 of 244.\n",
      "\n",
      "Evaluating...\n",
      "\tBatch  10 of  53.\n",
      "\tBatch  20 of  53.\n",
      "\tBatch  30 of  53.\n",
      "\tBatch  40 of  53.\n",
      "\tBatch  50 of  53.\n",
      "\n",
      "Training Loss: 0.226\n",
      "Training Time Taken: 10.59 seconds\n",
      "Validation Loss: 0.222\n",
      "Validation Time Taken: 2.17 seconds\n",
      "\n",
      "Epoch 35 of 50\n",
      "\tBatch  20 of 244.\n",
      "\tBatch  40 of 244.\n",
      "\tBatch  60 of 244.\n",
      "\tBatch  80 of 244.\n",
      "\tBatch 100 of 244.\n",
      "\tBatch 120 of 244.\n",
      "\tBatch 140 of 244.\n",
      "\tBatch 160 of 244.\n",
      "\tBatch 180 of 244.\n",
      "\tBatch 200 of 244.\n",
      "\tBatch 220 of 244.\n",
      "\tBatch 240 of 244.\n",
      "\n",
      "Evaluating...\n",
      "\tBatch  10 of  53.\n",
      "\tBatch  20 of  53.\n",
      "\tBatch  30 of  53.\n",
      "\tBatch  40 of  53.\n",
      "\tBatch  50 of  53.\n",
      "\n",
      "Training Loss: 0.228\n",
      "Training Time Taken: 10.72 seconds\n",
      "Validation Loss: 0.212\n",
      "Validation Time Taken: 2.21 seconds\n",
      "\n",
      "Epoch 36 of 50\n",
      "\tBatch  20 of 244.\n",
      "\tBatch  40 of 244.\n",
      "\tBatch  60 of 244.\n",
      "\tBatch  80 of 244.\n",
      "\tBatch 100 of 244.\n",
      "\tBatch 120 of 244.\n",
      "\tBatch 140 of 244.\n",
      "\tBatch 160 of 244.\n",
      "\tBatch 180 of 244.\n",
      "\tBatch 200 of 244.\n",
      "\tBatch 220 of 244.\n",
      "\tBatch 240 of 244.\n",
      "\n",
      "Evaluating...\n",
      "\tBatch  10 of  53.\n",
      "\tBatch  20 of  53.\n",
      "\tBatch  30 of  53.\n",
      "\tBatch  40 of  53.\n",
      "\tBatch  50 of  53.\n",
      "\n",
      "Training Loss: 0.217\n",
      "Training Time Taken: 11.02 seconds\n",
      "Validation Loss: 0.207\n",
      "Validation Time Taken: 2.24 seconds\n",
      "\n",
      "Epoch 37 of 50\n",
      "\tBatch  20 of 244.\n",
      "\tBatch  40 of 244.\n",
      "\tBatch  60 of 244.\n",
      "\tBatch  80 of 244.\n",
      "\tBatch 100 of 244.\n",
      "\tBatch 120 of 244.\n",
      "\tBatch 140 of 244.\n",
      "\tBatch 160 of 244.\n",
      "\tBatch 180 of 244.\n",
      "\tBatch 200 of 244.\n",
      "\tBatch 220 of 244.\n",
      "\tBatch 240 of 244.\n",
      "\n",
      "Evaluating...\n",
      "\tBatch  10 of  53.\n",
      "\tBatch  20 of  53.\n",
      "\tBatch  30 of  53.\n",
      "\tBatch  40 of  53.\n",
      "\tBatch  50 of  53.\n",
      "\n",
      "Training Loss: 0.216\n",
      "Training Time Taken: 10.96 seconds\n",
      "Validation Loss: 0.203\n",
      "Validation Time Taken: 2.38 seconds\n",
      "\n",
      "Epoch 38 of 50\n",
      "\tBatch  20 of 244.\n",
      "\tBatch  40 of 244.\n",
      "\tBatch  60 of 244.\n",
      "\tBatch  80 of 244.\n",
      "\tBatch 100 of 244.\n",
      "\tBatch 120 of 244.\n",
      "\tBatch 140 of 244.\n",
      "\tBatch 160 of 244.\n",
      "\tBatch 180 of 244.\n",
      "\tBatch 200 of 244.\n",
      "\tBatch 220 of 244.\n",
      "\tBatch 240 of 244.\n",
      "\n",
      "Evaluating...\n",
      "\tBatch  10 of  53.\n",
      "\tBatch  20 of  53.\n",
      "\tBatch  30 of  53.\n",
      "\tBatch  40 of  53.\n",
      "\tBatch  50 of  53.\n",
      "\n",
      "Training Loss: 0.213\n",
      "Training Time Taken: 11.06 seconds\n",
      "Validation Loss: 0.204\n",
      "Validation Time Taken: 2.17 seconds\n",
      "\n",
      "Epoch 39 of 50\n",
      "\tBatch  20 of 244.\n",
      "\tBatch  40 of 244.\n",
      "\tBatch  60 of 244.\n",
      "\tBatch  80 of 244.\n",
      "\tBatch 100 of 244.\n",
      "\tBatch 120 of 244.\n",
      "\tBatch 140 of 244.\n",
      "\tBatch 160 of 244.\n",
      "\tBatch 180 of 244.\n",
      "\tBatch 200 of 244.\n",
      "\tBatch 220 of 244.\n",
      "\tBatch 240 of 244.\n",
      "\n",
      "Evaluating...\n",
      "\tBatch  10 of  53.\n",
      "\tBatch  20 of  53.\n",
      "\tBatch  30 of  53.\n",
      "\tBatch  40 of  53.\n",
      "\tBatch  50 of  53.\n",
      "\n",
      "Training Loss: 0.204\n",
      "Training Time Taken: 11.17 seconds\n",
      "Validation Loss: 0.217\n",
      "Validation Time Taken: 2.18 seconds\n",
      "\n",
      "Epoch 40 of 50\n",
      "\tBatch  20 of 244.\n",
      "\tBatch  40 of 244.\n",
      "\tBatch  60 of 244.\n",
      "\tBatch  80 of 244.\n",
      "\tBatch 100 of 244.\n",
      "\tBatch 120 of 244.\n",
      "\tBatch 140 of 244.\n",
      "\tBatch 160 of 244.\n",
      "\tBatch 180 of 244.\n",
      "\tBatch 200 of 244.\n",
      "\tBatch 220 of 244.\n",
      "\tBatch 240 of 244.\n",
      "\n",
      "Evaluating...\n",
      "\tBatch  10 of  53.\n",
      "\tBatch  20 of  53.\n",
      "\tBatch  30 of  53.\n",
      "\tBatch  40 of  53.\n",
      "\tBatch  50 of  53.\n",
      "\n",
      "Training Loss: 0.210\n",
      "Training Time Taken: 10.88 seconds\n",
      "Validation Loss: 0.209\n",
      "Validation Time Taken: 2.17 seconds\n",
      "\n",
      "Epoch 41 of 50\n",
      "\tBatch  20 of 244.\n",
      "\tBatch  40 of 244.\n",
      "\tBatch  60 of 244.\n",
      "\tBatch  80 of 244.\n",
      "\tBatch 100 of 244.\n",
      "\tBatch 120 of 244.\n",
      "\tBatch 140 of 244.\n",
      "\tBatch 160 of 244.\n",
      "\tBatch 180 of 244.\n",
      "\tBatch 200 of 244.\n",
      "\tBatch 220 of 244.\n",
      "\tBatch 240 of 244.\n",
      "\n",
      "Evaluating...\n",
      "\tBatch  10 of  53.\n",
      "\tBatch  20 of  53.\n",
      "\tBatch  30 of  53.\n",
      "\tBatch  40 of  53.\n",
      "\tBatch  50 of  53.\n",
      "\n",
      "Training Loss: 0.210\n",
      "Training Time Taken: 10.74 seconds\n",
      "Validation Loss: 0.215\n",
      "Validation Time Taken: 2.17 seconds\n",
      "\n",
      "Epoch 42 of 50\n",
      "\tBatch  20 of 244.\n",
      "\tBatch  40 of 244.\n",
      "\tBatch  60 of 244.\n",
      "\tBatch  80 of 244.\n",
      "\tBatch 100 of 244.\n",
      "\tBatch 120 of 244.\n",
      "\tBatch 140 of 244.\n",
      "\tBatch 160 of 244.\n",
      "\tBatch 180 of 244.\n",
      "\tBatch 200 of 244.\n",
      "\tBatch 220 of 244.\n",
      "\tBatch 240 of 244.\n",
      "\n",
      "Evaluating...\n",
      "\tBatch  10 of  53.\n",
      "\tBatch  20 of  53.\n",
      "\tBatch  30 of  53.\n",
      "\tBatch  40 of  53.\n",
      "\tBatch  50 of  53.\n",
      "\n",
      "Training Loss: 0.204\n",
      "Training Time Taken: 10.90 seconds\n",
      "Validation Loss: 0.208\n",
      "Validation Time Taken: 2.18 seconds\n",
      "\n",
      "Epoch 43 of 50\n",
      "\tBatch  20 of 244.\n",
      "\tBatch  40 of 244.\n",
      "\tBatch  60 of 244.\n",
      "\tBatch  80 of 244.\n",
      "\tBatch 100 of 244.\n",
      "\tBatch 120 of 244.\n",
      "\tBatch 140 of 244.\n",
      "\tBatch 160 of 244.\n",
      "\tBatch 180 of 244.\n",
      "\tBatch 200 of 244.\n",
      "\tBatch 220 of 244.\n",
      "\tBatch 240 of 244.\n",
      "\n",
      "Evaluating...\n",
      "\tBatch  10 of  53.\n",
      "\tBatch  20 of  53.\n",
      "\tBatch  30 of  53.\n",
      "\tBatch  40 of  53.\n",
      "\tBatch  50 of  53.\n",
      "\n",
      "Training Loss: 0.207\n",
      "Training Time Taken: 11.24 seconds\n",
      "Validation Loss: 0.212\n",
      "Validation Time Taken: 2.18 seconds\n",
      "\n",
      "Epoch 44 of 50\n",
      "\tBatch  20 of 244.\n",
      "\tBatch  40 of 244.\n",
      "\tBatch  60 of 244.\n",
      "\tBatch  80 of 244.\n",
      "\tBatch 100 of 244.\n",
      "\tBatch 120 of 244.\n",
      "\tBatch 140 of 244.\n",
      "\tBatch 160 of 244.\n",
      "\tBatch 180 of 244.\n",
      "\tBatch 200 of 244.\n",
      "\tBatch 220 of 244.\n",
      "\tBatch 240 of 244.\n",
      "\n",
      "Evaluating...\n",
      "\tBatch  10 of  53.\n",
      "\tBatch  20 of  53.\n",
      "\tBatch  30 of  53.\n",
      "\tBatch  40 of  53.\n",
      "\tBatch  50 of  53.\n",
      "\n",
      "Training Loss: 0.220\n",
      "Training Time Taken: 10.89 seconds\n",
      "Validation Loss: 0.223\n",
      "Validation Time Taken: 2.22 seconds\n",
      "\n",
      "Epoch 45 of 50\n",
      "\tBatch  20 of 244.\n",
      "\tBatch  40 of 244.\n",
      "\tBatch  60 of 244.\n",
      "\tBatch  80 of 244.\n",
      "\tBatch 100 of 244.\n",
      "\tBatch 120 of 244.\n",
      "\tBatch 140 of 244.\n",
      "\tBatch 160 of 244.\n",
      "\tBatch 180 of 244.\n",
      "\tBatch 200 of 244.\n",
      "\tBatch 220 of 244.\n",
      "\tBatch 240 of 244.\n",
      "\n",
      "Evaluating...\n",
      "\tBatch  10 of  53.\n",
      "\tBatch  20 of  53.\n",
      "\tBatch  30 of  53.\n",
      "\tBatch  40 of  53.\n",
      "\tBatch  50 of  53.\n",
      "\n",
      "Training Loss: 0.200\n",
      "Training Time Taken: 10.82 seconds\n",
      "Validation Loss: 0.191\n",
      "Validation Time Taken: 2.18 seconds\n",
      "\n",
      "Epoch 46 of 50\n",
      "\tBatch  20 of 244.\n",
      "\tBatch  40 of 244.\n",
      "\tBatch  60 of 244.\n",
      "\tBatch  80 of 244.\n",
      "\tBatch 100 of 244.\n",
      "\tBatch 120 of 244.\n",
      "\tBatch 140 of 244.\n",
      "\tBatch 160 of 244.\n",
      "\tBatch 180 of 244.\n",
      "\tBatch 200 of 244.\n",
      "\tBatch 220 of 244.\n",
      "\tBatch 240 of 244.\n",
      "\n",
      "Evaluating...\n",
      "\tBatch  10 of  53.\n",
      "\tBatch  20 of  53.\n",
      "\tBatch  30 of  53.\n",
      "\tBatch  40 of  53.\n",
      "\tBatch  50 of  53.\n",
      "\n",
      "Training Loss: 0.204\n",
      "Training Time Taken: 11.03 seconds\n",
      "Validation Loss: 0.195\n",
      "Validation Time Taken: 2.19 seconds\n",
      "\n",
      "Epoch 47 of 50\n",
      "\tBatch  20 of 244.\n",
      "\tBatch  40 of 244.\n",
      "\tBatch  60 of 244.\n",
      "\tBatch  80 of 244.\n",
      "\tBatch 100 of 244.\n",
      "\tBatch 120 of 244.\n",
      "\tBatch 140 of 244.\n",
      "\tBatch 160 of 244.\n",
      "\tBatch 180 of 244.\n",
      "\tBatch 200 of 244.\n",
      "\tBatch 220 of 244.\n",
      "\tBatch 240 of 244.\n",
      "\n",
      "Evaluating...\n",
      "\tBatch  10 of  53.\n",
      "\tBatch  20 of  53.\n",
      "\tBatch  30 of  53.\n",
      "\tBatch  40 of  53.\n",
      "\tBatch  50 of  53.\n",
      "\n",
      "Training Loss: 0.194\n",
      "Training Time Taken: 10.68 seconds\n",
      "Validation Loss: 0.190\n",
      "Validation Time Taken: 2.19 seconds\n",
      "\n",
      "Epoch 48 of 50\n",
      "\tBatch  20 of 244.\n",
      "\tBatch  40 of 244.\n",
      "\tBatch  60 of 244.\n",
      "\tBatch  80 of 244.\n",
      "\tBatch 100 of 244.\n",
      "\tBatch 120 of 244.\n",
      "\tBatch 140 of 244.\n",
      "\tBatch 160 of 244.\n",
      "\tBatch 180 of 244.\n",
      "\tBatch 200 of 244.\n",
      "\tBatch 220 of 244.\n",
      "\tBatch 240 of 244.\n",
      "\n",
      "Evaluating...\n",
      "\tBatch  10 of  53.\n",
      "\tBatch  20 of  53.\n",
      "\tBatch  30 of  53.\n",
      "\tBatch  40 of  53.\n",
      "\tBatch  50 of  53.\n",
      "\n",
      "Training Loss: 0.194\n",
      "Training Time Taken: 10.68 seconds\n",
      "Validation Loss: 0.200\n",
      "Validation Time Taken: 2.18 seconds\n",
      "\n",
      "Epoch 49 of 50\n",
      "\tBatch  20 of 244.\n",
      "\tBatch  40 of 244.\n",
      "\tBatch  60 of 244.\n",
      "\tBatch  80 of 244.\n",
      "\tBatch 100 of 244.\n",
      "\tBatch 120 of 244.\n",
      "\tBatch 140 of 244.\n",
      "\tBatch 160 of 244.\n",
      "\tBatch 180 of 244.\n",
      "\tBatch 200 of 244.\n",
      "\tBatch 220 of 244.\n",
      "\tBatch 240 of 244.\n",
      "\n",
      "Evaluating...\n",
      "\tBatch  10 of  53.\n",
      "\tBatch  20 of  53.\n",
      "\tBatch  30 of  53.\n",
      "\tBatch  40 of  53.\n",
      "\tBatch  50 of  53.\n",
      "\n",
      "Training Loss: 0.196\n",
      "Training Time Taken: 10.63 seconds\n",
      "Validation Loss: 0.178\n",
      "Validation Time Taken: 2.18 seconds\n",
      "\n",
      "Epoch 50 of 50\n",
      "\tBatch  20 of 244.\n",
      "\tBatch  40 of 244.\n",
      "\tBatch  60 of 244.\n",
      "\tBatch  80 of 244.\n",
      "\tBatch 100 of 244.\n",
      "\tBatch 120 of 244.\n",
      "\tBatch 140 of 244.\n",
      "\tBatch 160 of 244.\n",
      "\tBatch 180 of 244.\n",
      "\tBatch 200 of 244.\n",
      "\tBatch 220 of 244.\n",
      "\tBatch 240 of 244.\n",
      "\n",
      "Evaluating...\n",
      "\tBatch  10 of  53.\n",
      "\tBatch  20 of  53.\n",
      "\tBatch  30 of  53.\n",
      "\tBatch  40 of  53.\n",
      "\tBatch  50 of  53.\n",
      "\n",
      "Training Loss: 0.196\n",
      "Training Time Taken: 11.18 seconds\n",
      "Validation Loss: 0.189\n",
      "Validation Time Taken: 2.19 seconds\n",
      "\n",
      "Total Time Taken: 683.76 seconds\n"
     ]
    }
   ],
   "source": [
    "# Set initial loss to infinite\n",
    "bestValidationLoss = float('inf')\n",
    "\n",
    "# Empty lists to store training and validation loss of each epoch\n",
    "trainingLosses = []\n",
    "validationLosses = []\n",
    "\n",
    "# Initialize total time taken to 0\n",
    "totalTimeTaken = 0\n",
    "\n",
    "# For each epoch\n",
    "for epoch in range(epochs):\n",
    "    print('\\nEpoch {:} of {:}'.format(epoch + 1, epochs))\n",
    "    \n",
    "    # Train model and record time taken\n",
    "    startTime = time.time()\n",
    "    trainingLoss, _ = train()\n",
    "    trainingTimeTaken = time.time() - startTime\n",
    "\n",
    "    # Evaluate model and record time taken\n",
    "    startTime = time.time()\n",
    "    validationLoss, _ = evaluate()\n",
    "    validationTimeTaken = time.time() - startTime\n",
    "\n",
    "    # Save the best model\n",
    "    if validationLoss < bestValidationLoss:\n",
    "        bestValidationLoss = validationLoss\n",
    "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
    "    \n",
    "    # Append training and validation losses\n",
    "    trainingLosses.append(trainingLoss)\n",
    "    validationLosses.append(validationLoss)\n",
    "    \n",
    "    # Print epoch results and times taken\n",
    "    print(f'\\nTraining Loss: {trainingLoss:.3f}')\n",
    "    print(f'Training Time Taken: {trainingTimeTaken:.2f} seconds')\n",
    "    print(f'Validation Loss: {validationLoss:.3f}')\n",
    "    print(f'Validation Time Taken: {validationTimeTaken:.2f} seconds')\n",
    "\n",
    "    # Update total time taken\n",
    "    totalTimeTaken += trainingTimeTaken + validationTimeTaken\n",
    "\n",
    "# Print total time taken for all epochs\n",
    "print(f'\\nTotal Time Taken: {totalTimeTaken:.2f} seconds')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Trained Model to Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions for test data\n",
    "with torch.no_grad():\n",
    "    preds = model(testSequenceTensor.to(device), testMaskTensor.to(device))\n",
    "    preds = preds.detach().cpu().numpy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Model's Performance on Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       724\n",
      "           1       0.86      0.89      0.88       112\n",
      "\n",
      "    accuracy                           0.97       836\n",
      "   macro avg       0.92      0.94      0.93       836\n",
      "weighted avg       0.97      0.97      0.97       836\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model's performance\n",
    "predications = np.argmax(preds, axis=1)\n",
    "print(classification_report(testYTensor, predications))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol>\n",
    "    <li><a href=\"https://www.reddit.com/r/MachineLearning/comments/ao23cp/p_how_to_use_bert_in_kaggle_competitions_a/\">How to use BERT in Kaggle competitions - Reddit Thread</a></li>\n",
    "    <li><a href=\"http://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/\">A visual guide to using BERT by Jay Alammar</a></li>\n",
    "    <li><a href=\"https://www.analyticsvidhya.com/blog/2019/09/demystifying-bert-groundbreaking-nlp-framework/\">Demystifying BERT: Groundbreaking NLP Framework by Mohd Sanad Zaki Rizvi</a></li>\n",
    "    <li><a href=\"https://towardsdatascience.com/bert-for-dummies-step-by-step-tutorial-fb90890ffe03\">BERT for Dummies step by step tutorial by Michel Kana</a></li>\n",
    "</ol>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
