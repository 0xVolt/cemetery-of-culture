{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/0xVolt/cemetery-of-culture/blob/main/year-3/neural-networks/6-sentiment-analysis/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nTs2MRi7LMK9"
      },
      "outputs": [],
      "source": [
        "# Importing the required libs\n",
        "import numpy as np  # linear algebra\n",
        "import pandas as pd  # data processing\n",
        "import keras\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import re\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "opIiYpwa55v3"
      },
      "source": [
        "only keeping the required coloumns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "YYY_SbAs5-QV"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('Sentiment.csv')\n",
        "data = data[['text', 'sentiment']]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rl2W1m-XTtGJ",
        "outputId": "0e289eb5-f7f9-42e0-b1da-7b4c919d7c68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4472\n",
            "16986\n"
          ]
        }
      ],
      "source": [
        "data = data[data.sentiment != \"Neutral\"]\n",
        "data['text'] = data['text'].apply(lambda x: x.lower())\n",
        "data['text'] = data['text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]', '', x)))\n",
        "\n",
        "print(data[data['sentiment'] == 'Positive'].size)\n",
        "print(data[data['sentiment'] == 'Negative'].size)\n",
        "\n",
        "for idx, row in data.iterrows():\n",
        "    row[0] = row[0].replace('rt', ' ')\n",
        "\n",
        "max_fatures = 2000\n",
        "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
        "tokenizer.fit_on_texts(data['text'].values)\n",
        "X = tokenizer.texts_to_sequences(data['text'].values)\n",
        "X = pad_sequences(X)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "RM4Cs6lfUd9J"
      },
      "source": [
        "the variables embed_dim, lstm_out, batch_size, droupout_x are hyperparameters (the parameters used to control the learning process By contrast the values of the other parameters are derived via traning)thier values are intuitive and can be played with to achive better results\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "KwhNoFbjWdhw"
      },
      "source": [
        "softmax activation funtion is used as the network uses catagorical crossentropy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zl2Z48MXWzLT",
        "outputId": "fc7085b1-569f-4767-ac60-4a20e84fb549"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 28, 128)           256000    \n",
            "                                                                 \n",
            " spatial_dropout1d (SpatialD  (None, 28, 128)          0         \n",
            " ropout1D)                                                       \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 196)               254800    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 394       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 511,194\n",
            "Trainable params: 511,194\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "embed_dim = 128\n",
        "lstm_out = 196\n",
        "model = Sequential()  # each layer has one input tensor and one output tensor\n",
        "model.add(Embedding(max_fatures, embed_dim, input_length=X.shape[1]))\n",
        "\n",
        "# dropsout 1D feature maps insted of individual elements\n",
        "model.add(SpatialDropout1D(0.4))\n",
        "model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "QybHnSgad4T7"
      },
      "source": [
        "traning and testing dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIx-QwU0d8Th",
        "outputId": "9edf4777-c135-428e-8e7f-3e38697e3d8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(7188, 28) (7188, 2)\n",
            "(3541, 28) (3541, 2)\n"
          ]
        }
      ],
      "source": [
        "Y = pd.get_dummies(data['sentiment']).values\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "    X, Y, test_size=0.33, random_state=42)\n",
        "print(X_train.shape, Y_train.shape)\n",
        "print(X_test.shape, Y_test.shape)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0b2Ljdj0idP7"
      },
      "source": [
        "traning the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "2siBzIGJh_3X",
        "outputId": "a2e92402-77d3-4ae4-8595-15235c0342c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "225/225 - 17s - loss: 0.4417 - accuracy: 0.8154 - 17s/epoch - 75ms/step\n",
            "Epoch 2/10\n",
            "225/225 - 14s - loss: 0.3217 - accuracy: 0.8638 - 14s/epoch - 64ms/step\n",
            "Epoch 3/10\n",
            "225/225 - 14s - loss: 0.2784 - accuracy: 0.8831 - 14s/epoch - 60ms/step\n",
            "Epoch 4/10\n",
            "225/225 - 12s - loss: 0.2502 - accuracy: 0.8972 - 12s/epoch - 52ms/step\n",
            "Epoch 5/10\n",
            "225/225 - 11s - loss: 0.2288 - accuracy: 0.9064 - 11s/epoch - 50ms/step\n",
            "Epoch 6/10\n",
            "225/225 - 12s - loss: 0.2026 - accuracy: 0.9175 - 12s/epoch - 54ms/step\n",
            "Epoch 7/10\n",
            "225/225 - 13s - loss: 0.1785 - accuracy: 0.9290 - 13s/epoch - 57ms/step\n",
            "Epoch 8/10\n",
            "225/225 - 14s - loss: 0.1608 - accuracy: 0.9349 - 14s/epoch - 62ms/step\n",
            "Epoch 9/10\n",
            "225/225 - 12s - loss: 0.1508 - accuracy: 0.9371 - 12s/epoch - 52ms/step\n",
            "Epoch 10/10\n"
          ]
        }
      ],
      "source": [
        "batch_size = 32\n",
        "model.fit(X_train, Y_train, epochs=10, batch_size=batch_size, verbose=2)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "EfrCpfFBiXBN"
      },
      "source": [
        "extracting a validation set and mesuring the score and accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hjcCtqliiGQF",
        "outputId": "49c00213-1079-476d-b4f2-aefb3707b153"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "64/64 - 2s - loss: 0.5063 - accuracy: 0.8236 - 2s/epoch - 24ms/step\n",
            "score: 0.51\n",
            "acc: 0.82\n"
          ]
        }
      ],
      "source": [
        "validation_size = 1500\n",
        "\n",
        "X_validate = X_test[-validation_size:]\n",
        "Y_validate = Y_test[-validation_size:]\n",
        "X_test = X_test[:-validation_size]\n",
        "Y_test = Y_test[:-validation_size]\n",
        "score, acc = model.evaluate(X_test, Y_test, verbose=2, batch_size=batch_size)\n",
        "print(\"score: %.2f\" % (score))\n",
        "print(\"acc: %.2f\" % (acc))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pkcdkJgmiNVd"
      },
      "outputs": [],
      "source": [
        "pos_cnt, neg_cnt, pos_correct, neg_correct = 0, 0, 0, 0\n",
        "for x in range(len(X_validate)):\n",
        "\n",
        "    result = model.predict(X_validate[x].reshape(\n",
        "        1, X_test.shape[1]), batch_size=1, verbose=2)[0]\n",
        "\n",
        "    if np.argmax(result) == np.argmax(Y_validate[x]):\n",
        "        if np.argmax(Y_validate[x]) == 0:\n",
        "            neg_correct += 1\n",
        "        else:\n",
        "            pos_correct += 1\n",
        "\n",
        "    if np.argmax(Y_validate[x]) == 0:\n",
        "        neg_cnt += 1\n",
        "    else:\n",
        "        pos_cnt += 1\n",
        "\n",
        "print(\"pos_acc\", pos_correct/pos_cnt*100, \"%\")\n",
        "print(\"neg_acc\", neg_correct/neg_cnt*100, \"%\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7 (tags/v3.10.7:6cc6b13, Sep  5 2022, 14:08:36) [MSC v.1933 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "3a00e68b57149134ce2b73879182c8cdd95184339958c7ea15c51bb9d3595f11"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
